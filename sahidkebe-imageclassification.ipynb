{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e74caf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T03:53:45.057936Z",
     "iopub.status.busy": "2022-03-29T03:53:45.057199Z",
     "iopub.status.idle": "2022-03-29T03:53:46.427445Z",
     "shell.execute_reply": "2022-03-29T03:53:46.426746Z",
     "shell.execute_reply.started": "2022-03-29T03:53:05.421654Z"
    },
    "papermill": {
     "duration": 1.39708,
     "end_time": "2022-03-29T03:53:46.427601",
     "exception": false,
     "start_time": "2022-03-29T03:53:45.030521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, random_split, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef916b",
   "metadata": {
    "papermill": {
     "duration": 0.014057,
     "end_time": "2022-03-29T03:53:46.459504",
     "exception": false,
     "start_time": "2022-03-29T03:53:46.445447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729fb9da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T03:53:46.495946Z",
     "iopub.status.busy": "2022-03-29T03:53:46.495301Z",
     "iopub.status.idle": "2022-03-29T03:53:47.848361Z",
     "shell.execute_reply": "2022-03-29T03:53:47.847435Z",
     "shell.execute_reply.started": "2022-03-29T03:53:05.513045Z"
    },
    "papermill": {
     "duration": 1.374752,
     "end_time": "2022-03-29T03:53:47.848644",
     "exception": true,
     "start_time": "2022-03-29T03:53:46.473892",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/2838263412.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdirectories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directories = ['../input/csc4851-homework4/birds_400/test',\n",
    "                                '../input/csc4851-homework4/birds_400/train',\n",
    "                                '../input//csc4851-homework4/birds_400/valid']\n",
    "\n",
    "for dir in directories:\n",
    "    label = []\n",
    "    path = []\n",
    "    for dirname, _,filenames in os.walk(dir):\n",
    "        for filename in filenames:\n",
    "            label.append(os.path.split(dirname)[1])\n",
    "            path.append(os.path.join(dirname,filename))\n",
    "    if dir == directories[0]:\n",
    "        df_test = pd.DataFrame(columns=['path','label'])\n",
    "        df_test['path']=path\n",
    "        df_test['label']=label\n",
    "    elif dir == directories[1]:\n",
    "        df_train = pd.DataFrame(columns=['path','label'])\n",
    "        df_train['path']=path\n",
    "        df_train['label']=label        \n",
    "    elif dir == directories[2]:\n",
    "        df_valid = pd.DataFrame(columns=['path','label'])\n",
    "        df_valid['path']=path\n",
    "        df_valid['label']=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c81b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T03:53:06.967748Z",
     "iopub.status.busy": "2022-03-29T03:53:06.967398Z",
     "iopub.status.idle": "2022-03-29T03:53:06.978487Z",
     "shell.execute_reply": "2022-03-29T03:53:06.977471Z",
     "shell.execute_reply.started": "2022-03-29T03:53:06.967705Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd069da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T03:53:06.980414Z",
     "iopub.status.busy": "2022-03-29T03:53:06.980003Z",
     "iopub.status.idle": "2022-03-29T03:53:08.082561Z",
     "shell.execute_reply": "2022-03-29T03:53:08.081818Z",
     "shell.execute_reply.started": "2022-03-29T03:53:06.980382Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Display 20 picture of the dataset with their labels\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 7),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "df_sample = df_train.sample(15)\n",
    "df_sample.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(df_sample.path[i]))\n",
    "    ax.set_title(df_sample.label[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e540634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T03:53:08.085373Z",
     "iopub.status.busy": "2022-03-29T03:53:08.084626Z",
     "iopub.status.idle": "2022-03-29T03:53:08.090726Z",
     "shell.execute_reply": "2022-03-29T03:53:08.089776Z",
     "shell.execute_reply.started": "2022-03-29T03:53:08.085331Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_iters = 30\n",
    "epochs  = 10#int( n_iters / (len(train_dl) / batch_size))\n",
    "input_dim = 784\n",
    "output_dim = 10\n",
    "lr_rate  = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee2e654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T03:53:08.092766Z",
     "iopub.status.busy": "2022-03-29T03:53:08.092022Z",
     "iopub.status.idle": "2022-03-29T03:53:08.102020Z",
     "shell.execute_reply": "2022-03-29T03:53:08.101141Z",
     "shell.execute_reply.started": "2022-03-29T03:53:08.092730Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ccf879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T03:53:08.103596Z",
     "iopub.status.busy": "2022-03-29T03:53:08.103317Z",
     "iopub.status.idle": "2022-03-29T03:53:08.118040Z",
     "shell.execute_reply": "2022-03-29T03:53:08.117036Z",
     "shell.execute_reply.started": "2022-03-29T03:53:08.103528Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc708ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T03:53:08.119785Z",
     "iopub.status.busy": "2022-03-29T03:53:08.119467Z",
     "iopub.status.idle": "2022-03-29T03:53:09.042349Z",
     "shell.execute_reply": "2022-03-29T03:53:09.041533Z",
     "shell.execute_reply.started": "2022-03-29T03:53:08.119755Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = \"../input/csc4851-homework4/birds_400/train\"\n",
    "val_path = \"../input/csc4851-homework4/birds_400/valid\"\n",
    "test_path = \"../input/csc4851-homework4/birds_400/test\"\n",
    "batch_size = 64\n",
    "transform = transforms.Compose([\n",
    "  #  transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "train_folder = torchvision.datasets.ImageFolder(root=train_path, transform=transform)\n",
    "valid_folder = torchvision.datasets.ImageFolder(root=val_path, transform=transform)\n",
    "test_folder = torchvision.datasets.ImageFolder(root=test_path, transform=transform)\n",
    "train_ds = DataLoader(train_folder, batch_size=batch_size)\n",
    "valid_ds = DataLoader(valid_folder, batch_size=batch_size)\n",
    "test_ds = DataLoader(test_folder, batch_size=batch_size)\n",
    "\n",
    "CLASSES = list(train_folder.class_to_idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05878f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T03:53:09.044018Z",
     "iopub.status.busy": "2022-03-29T03:53:09.043680Z",
     "iopub.status.idle": "2022-03-29T03:53:09.055428Z",
     "shell.execute_reply": "2022-03-29T03:53:09.054870Z",
     "shell.execute_reply.started": "2022-03-29T03:53:09.043979Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 11, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e39755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T03:53:09.056731Z",
     "iopub.status.busy": "2022-03-29T03:53:09.056484Z",
     "iopub.status.idle": "2022-03-29T03:53:09.779041Z",
     "shell.execute_reply": "2022-03-29T03:53:09.778289Z",
     "shell.execute_reply.started": "2022-03-29T03:53:09.056703Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_classes = len(train_folder.classes)\n",
    "model = CNNModel(n_classes)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2fa072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T03:53:09.781589Z",
     "iopub.status.busy": "2022-03-29T03:53:09.781365Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "train_steps = len(train_ds)\n",
    "valid_steps = len(valid_ds)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "metrics = {\"loss\": [], \"val_loss\": [], \"val_accuracy\": []}\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    model.train()\n",
    "    begin = time.time()\n",
    "    for batch in train_ds:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.data.item())\n",
    "        if len(train_losses) > 0 and len(train_losses) % 20 == 0:\n",
    "            current = time.time()\n",
    "            elapsed = current - begin\n",
    "            print(\"Epoch %d: [Training] %.2fs/%.2fs\"%(epoch + 1, elapsed, elapsed / float(len(train_losses)) * train_steps))\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    begin = time.time()\n",
    "    for batch in valid_ds:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, targets)\n",
    "        valid_losses.append(loss.data.item())\n",
    "        correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n",
    "        num_correct += torch.sum(correct).item()\n",
    "        num_samples += correct.shape[0]\n",
    "        if len(valid_losses) > 0 and len(valid_losses) % 10 == 0:\n",
    "            current = time.time()\n",
    "            elapsed = current - begin\n",
    "            print(\"Epoch %d: [Validation] %.2fs/%.2fs\"%(epoch + 1, elapsed, elapsed / float(len(valid_losses)) * valid_steps))\n",
    "    train_loss = torch.mean(torch.Tensor(train_losses)).item()\n",
    "    valid_loss = torch.mean(torch.Tensor(valid_losses)).item()\n",
    "    accuracy = num_correct / num_samples if num_samples > 0 else 0\n",
    "    metrics[\"loss\"].append(train_loss)\n",
    "    metrics[\"val_loss\"].append(valid_loss)\n",
    "    metrics[\"val_accuracy\"].append(accuracy)\n",
    "    print(\"Training Loss: %.2f Validation Loss: %.2f accuracy: %.2f\" %(train_loss, valid_loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a664db5d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f3967f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Pretrained Classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a32f4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PreTrainedClassifier(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pretrained model\n",
    "        self.network = models.resnet34(pretrained=True)\n",
    "        # Replace last layer\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs, len(CLASSES))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return torch.sigmoid(self.network(xb))\n",
    "    \n",
    "    def freeze(self):\n",
    "        # To freeze the residual layers\n",
    "        for param in self.network.parameters():\n",
    "            param.require_grad = False\n",
    "        for param in self.network.fc.parameters():\n",
    "            param.require_grad = True\n",
    "    \n",
    "    def unfreeze(self):\n",
    "        # Unfreeze all layers\n",
    "        for param in self.network.parameters():\n",
    "            param.require_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41324b6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    # Set up cutom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in tqdm(train_loader):\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        result['model'] = 'pre-trained-model'\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604dff91",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = to_device(PreTrainedClassifier(), device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d658fc2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0592db",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272ea02",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'Accuracy': accuracy, 'Name': df.head()})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.130614,
   "end_time": "2022-03-29T03:53:48.574773",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-29T03:53:36.444159",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
